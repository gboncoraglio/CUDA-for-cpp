{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Unified Memory.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dBK9SeW2-QX4","colab_type":"text"},"source":["#### <h1><div align=\"center\">Managing Accelerated Application Memory with CUDA C/C++ Unified Memory</div></h1>"]},{"cell_type":"code","metadata":{"id":"e2Srf-qt-Uuh","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/CUDA for Cpp/Managing C:Cpp with CUDA Unified Memory and nsys')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bFZFfu3F-QX5","colab_type":"text"},"source":["It is highly recommended a design cycle called **APOD**: **A**ssess, **P**arallelize, **O**ptimize, **D**eploy. In short, APOD prescribes an iterative design process, where developers can apply incremental improvements to their accelerated application's performance, and ship their code. \n"]},{"cell_type":"markdown","metadata":{"id":"wWDOKj2C-QX7","colab_type":"text"},"source":["---\n","## Iterative Optimizations with the NVIDIA Command Line Profiler\n","\n","The only way to be assured that attempts at optimizing accelerated code bases are actually successful is to profile the application for quantitative information about the application's performance. `nsys` is the Nsight Systems command line tool. It ships with the CUDA toolkit.\n","\n","`nsys` is easy to use. Its most basic usage is to simply pass it the path to an executable compiled with `nvcc`. `nsys` will proceed to execute the application, after which it will print a summary output of the application's GPU activities, CUDA API calls, as well as information about **Unified Memory** activity, a topic which will be covered extensively later in this lab.\n"]},{"cell_type":"markdown","metadata":{"id":"ouhEkLqL-QX8","colab_type":"text"},"source":["### Profile an Application with nsys\n","\n","The first code execution cell will compile (and run) the vector addition program. The second code execution cell will profile the executable that was just compiled using `nsys profile`.\n","\n","`nsys profile` will generate a `qdrep` report file which can be used in a variety of manners. We use the `--stats=true` flag here to indicate we would like summary statistics printed. There is quite a lot of information printed:\n","\n","- Profile configuration details\n","- Report file(s) generation details\n","- **CUDA API Statistics**\n","- **CUDA Kernel Statistics**\n","- **CUDA Memory Operation Statistics (time and size)**\n","- OS Runtime API Statistics\n","\n","Here we focus on the 3 sections in **bold** above."]},{"cell_type":"markdown","metadata":{"id":"EJrfslRZ-QX8","colab_type":"text"},"source":["After profiling the application, answer the following questions using information displayed in the profiling output:\n","\n","- What was the name of the only CUDA kernel called in this application?\n","addVectorsInto\n","- How many times did this kernel run?\n","- How long did it take this kernel to run? "]},{"cell_type":"code","metadata":{"id":"12xbCksV-QX9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e77a7b87-d96c-4305-b1d0-058d73c2bf6d","executionInfo":{"status":"ok","timestamp":1591051380434,"user_tz":420,"elapsed":7711,"user":{"displayName":"Gabriele Boncoraglio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXEw7TWB8AnQR7GBopOPG42CBDV3rLZ-UejvU5SA=s64","userId":"05926223390448651175"}}},"source":["!nvcc -o single-thread-vector-add 01-vector-add.cu -run"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Success! All values calculated correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BrcCTxCh-QYB","colab_type":"code","colab":{},"outputId":"8bb1bcb9-e5b1-47d3-d609-102557f7f51f"},"source":["!nsys profile --stats=true ./single-thread-vector-add"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","**** collection configuration ****\n","\tforce-overwrite = false\n","\tstop-on-exit = true\n","\texport_sqlite = true\n","\tstats = true\n","\tcapture-range = none\n","\tstop-on-range-end = false\n","\tBeta: ftrace events:\n","\tftrace-keep-user-config = false\n","\ttrace-GPU-context-switch = false\n","\tdelay = 0 seconds\n","\tduration = 0 seconds\n","\tkill = signal number 15\n","\tinherit-environment = true\n","\tshow-output = true\n","\ttrace-fork-before-exec = false\n","\tsample_cpu = true\n","\tbacktrace_method = LBR\n","\twait = all\n","\ttrace_cublas = false\n","\ttrace_cuda = true\n","\ttrace_cudnn = false\n","\ttrace_nvtx = true\n","\ttrace_mpi = false\n","\ttrace_openacc = false\n","\ttrace_vulkan = false\n","\ttrace_opengl = true\n","\ttrace_osrt = true\n","\tosrt-threshold = 0 nanoseconds\n","\tcudabacktrace = false\n","\tcudabacktrace-threshold = 0 nanoseconds\n","\tprofile_processes = tree\n","\tapplication command = ./single-thread-vector-add\n","\tapplication arguments = \n","\tapplication working directory = /dli/task\n","\tNVTX profiler range trigger = \n","\tNVTX profiler domain trigger = \n","\tenvironment variables:\n","\tCollecting data...\n","Success! All values calculated correctly.\n","\tGenerating the /dli/task/report1.qdstrm file.\n","\tCapturing raw events...\n","\t4618 total events collected.\n","\tSaving diagnostics...\n","\tSaving qdstrm file to disk...\n","\tFinished saving file.\n","\n","\n","Importing the qdstrm file using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/QdstrmImporter.\n","\n","Importing...\n","\n","Importing [==================================================100%]\n","Saving report to file \"/dli/task/report1.qdrep\"\n","Report file saved.\n","Please discard the qdstrm file and use the qdrep file instead.\n","\n","Removed /dli/task/report1.qdstrm as it was successfully imported.\n","Please use the qdrep file instead.\n","\n","Exporting the qdrep file to SQLite database using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/nsys-exporter.\n","\n","Exporting 4582 events:\n","\n","0%   10   20   30   40   50   60   70   80   90   100%\n","|----|----|----|----|----|----|----|----|----|----|\n","***************************************************\n","\n","Exported successfully to\n","/dli/task/report1.sqlite\n","\n","Generating CUDA API Statistics...\n","CUDA API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   89.0      2200467584           1    2200467584.0      2200467584      2200467584  cudaDeviceSynchronize                                                           \n","   10.0       246460746           3      82153582.0           28260       246381680  cudaMallocManaged                                                               \n","    1.0        24924541           3       8308180.3         7647956         9472147  cudaFree                                                                        \n","    0.0           83802           1         83802.0           83802           83802  cudaLaunchKernel                                                                \n","\n","\n","\n","\n","Generating CUDA Kernel Statistics...\n","\n","Generating CUDA Memory Operation Statistics...\n","CUDA Kernel Statistics (nanoseconds)\n","\n","Time(%)      Total Time   Instances         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","  100.0      2200462996           1    2200462996.0      2200462996      2200462996  addVectorsInto                                                                  \n","\n","\n","CUDA Memory Operation Statistics (nanoseconds)\n","\n","Time(%)      Total Time  Operations         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   78.9        42397984        2304         18401.9            2816          109376  [CUDA Unified Memory memcpy HtoD]                                               \n","   21.1        11319040         768         14738.3            1824           82432  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","CUDA Memory Operation Statistics (KiB)\n","\n","            Total      Operations            Average            Minimum            Maximum  Name                                                                            \n","-----------------  --------------  -----------------  -----------------  -----------------  --------------------------------------------------------------------------------\n","         393216.0            2304              170.7              4.000             1020.0  [CUDA Unified Memory memcpy HtoD]                                               \n","         131072.0             768              170.7              4.000             1020.0  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","\n","\n","Generating Operating System Runtime API Statistics...\n","Operating System Runtime API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   58.8      5382388203         275      19572320.7           48229       100185595  poll                                                                            \n","   40.0      3660055065         275      13309291.1           26667       100157382  sem_timedwait                                                                   \n","    1.0        88807868         579        153381.5            1030        20166968  ioctl                                                                           \n","    0.3        27315298          87        313968.9            1630         9413375  mmap                                                                            \n","    0.0          705680          73          9666.8            3733           26407  open64                                                                          \n","    0.0          148919           4         37229.8           34132           42185  pthread_create                                                                  \n","    0.0          127613          23          5548.4            2092           15087  fopen                                                                           \n","    0.0          109104          10         10910.4            7564           15479  write                                                                           \n","    0.0           90381           3         30127.0           21824           43665  fgets                                                                           \n","    0.0           83290          73          1141.0            1007            4535  fcntl                                                                           \n","    0.0           48681          13          3744.7            1695            5840  munmap                                                                          \n","    0.0           42132          16          2633.3            1686            4159  fclose                                                                          \n","    0.0           36927           5          7385.4            4524           11352  open                                                                            \n","    0.0           25043          12          2086.9            1235            4022  read                                                                            \n","    0.0           16661           3          5553.7            5022            6606  pipe2                                                                           \n","    0.0           11516           2          5758.0            5011            6505  socket                                                                          \n","    0.0            9414           4          2353.5            2152            2692  mprotect                                                                        \n","    0.0            7944           2          3972.0            3339            4605  fread                                                                           \n","    0.0            7565           1          7565.0            7565            7565  connect                                                                         \n","    0.0            2503           1          2503.0            2503            2503  bind                                                                            \n","    0.0            1775           1          1775.0            1775            1775  listen                                                                          \n","\n","\n","\n","\n","Generating NVTX Push-Pop Range Statistics...\n","NVTX Push-Pop Range Statistics (nanoseconds)\n","\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_riIzizg-QYE","colab_type":"text"},"source":["Worth mentioning is that by default, `nsys profile` will not overwrite an existing report file. This is done to prevent accidental loss of work when profiling. If for any reason, you would rather overwrite an existing report file, say during rapid iterations, you can provide th `-f` flag to `nsys profile` to allow overwriting an existing report file."]},{"cell_type":"markdown","metadata":{"id":"UcMwLGIh-QYF","colab_type":"text"},"source":["### Optimize and Profile\n","\n","Updating the code so that it runs on many threads in a single thread block. Recompile and then profile with `nsys profile --stats=true` using the code execution cells below. Use the profiling output to check the runtime of the kernel. "]},{"cell_type":"code","metadata":{"id":"YwfZK7VU-QYF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a56968e4-c812-4e54-f11d-da23435f9cf4","executionInfo":{"status":"ok","timestamp":1591051391675,"user_tz":420,"elapsed":5979,"user":{"displayName":"Gabriele Boncoraglio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXEw7TWB8AnQR7GBopOPG42CBDV3rLZ-UejvU5SA=s64","userId":"05926223390448651175"}}},"source":["!nvcc -o multi-thread-vector-add 01-vector-add.cu -run"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Success! All values calculated correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ImUSVGbJ-QYH","colab_type":"code","colab":{},"outputId":"c8c265d5-6c1a-4f97-d2e7-b7b686357edc"},"source":["!nsys profile --stats=true ./multi-thread-vector-add"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","**** collection configuration ****\n","\tforce-overwrite = false\n","\tstop-on-exit = true\n","\texport_sqlite = true\n","\tstats = true\n","\tcapture-range = none\n","\tstop-on-range-end = false\n","\tBeta: ftrace events:\n","\tftrace-keep-user-config = false\n","\ttrace-GPU-context-switch = false\n","\tdelay = 0 seconds\n","\tduration = 0 seconds\n","\tkill = signal number 15\n","\tinherit-environment = true\n","\tshow-output = true\n","\ttrace-fork-before-exec = false\n","\tsample_cpu = true\n","\tbacktrace_method = LBR\n","\twait = all\n","\ttrace_cublas = false\n","\ttrace_cuda = true\n","\ttrace_cudnn = false\n","\ttrace_nvtx = true\n","\ttrace_mpi = false\n","\ttrace_openacc = false\n","\ttrace_vulkan = false\n","\ttrace_opengl = true\n","\ttrace_osrt = true\n","\tosrt-threshold = 0 nanoseconds\n","\tcudabacktrace = false\n","\tcudabacktrace-threshold = 0 nanoseconds\n","\tprofile_processes = tree\n","\tapplication command = ./multi-thread-vector-add\n","\tapplication arguments = \n","\tapplication working directory = /dli/task\n","\tNVTX profiler range trigger = \n","\tNVTX profiler domain trigger = \n","\tenvironment variables:\n","\tCollecting data...\n","Success! All values calculated correctly.\n","\tGenerating the /dli/task/report2.qdstrm file.\n","\tCapturing raw events...\n","\t4239 total events collected.\n","\tSaving diagnostics...\n","\tSaving qdstrm file to disk...\n","\tFinished saving file.\n","\n","\n","Importing the qdstrm file using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/QdstrmImporter.\n","\n","Importing...\n","\n","Importing [==================================================100%]\n","Saving report to file \"/dli/task/report2.qdrep\"\n","Report file saved.\n","Please discard the qdstrm file and use the qdrep file instead.\n","\n","Removed /dli/task/report2.qdstrm as it was successfully imported.\n","Please use the qdrep file instead.\n","\n","Exporting the qdrep file to SQLite database using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/nsys-exporter.\n","\n","Exporting 4201 events:\n","\n","0%   10   20   30   40   50   60   70   80   90   100%\n","|----|----|----|----|----|----|----|----|----|----|\n","***************************************************\n","\n","Exported successfully to\n","/dli/task/report2.sqlite\n","\n","Generating CUDA API Statistics...\n","CUDA API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   60.1       247087633           3      82362544.3           27586       247006076  cudaMallocManaged                                                               \n","   33.8       138942458           1     138942458.0       138942458       138942458  cudaDeviceSynchronize                                                           \n","    6.1        25073475           3       8357825.0         7699356         9551508  cudaFree                                                                        \n","    0.0           78259           1         78259.0           78259           78259  cudaLaunchKernel                                                                \n","\n","\n","\n","\n","Generating CUDA Kernel Statistics...\n","\n","Generating CUDA Memory Operation Statistics...\n","CUDA Kernel Statistics (nanoseconds)\n","\n","Time(%)      Total Time   Instances         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","  100.0       138940268           1     138940268.0       138940268       138940268  addVectorsInto                                                                  \n","\n","\n","CUDA Memory Operation Statistics (nanoseconds)\n","\n","Time(%)      Total Time  Operations         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   78.9        42606848        2304         18492.6            2880          109088  [CUDA Unified Memory memcpy HtoD]                                               \n","   21.1        11403456         768         14848.3            1888           82528  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","CUDA Memory Operation Statistics (KiB)\n","\n","            Total      Operations            Average            Minimum            Maximum  Name                                                                            \n","-----------------  --------------  -----------------  -----------------  -----------------  --------------------------------------------------------------------------------\n","         393216.0            2304              170.7              4.000             1020.0  [CUDA Unified Memory memcpy HtoD]                                               \n","         131072.0             768              170.7              4.000             1020.0  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","\n","\n","Generating Operating System Runtime API Statistics...\n","Operating System Runtime API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   55.2      1679581492          87      19305534.4           49666       100188242  poll                                                                            \n","   40.9      1244186625          87      14300995.7           22366       100124191  sem_timedwait                                                                   \n","    3.0        89811259         576        155922.3            1044        20091683  ioctl                                                                           \n","    0.9        27464129          87        315679.6            1472         9496801  mmap                                                                            \n","    0.0          651125          73          8919.5            3764           26209  open64                                                                          \n","    0.0          151891           4         37972.7           34799           43780  pthread_create                                                                  \n","    0.0          131652          23          5724.0            1605           19160  fopen                                                                           \n","    0.0          112887          10         11288.7            7649           17690  write                                                                           \n","    0.0           89748           3         29916.0           21519           44022  fgets                                                                           \n","    0.0           80799          71          1138.0            1000            5385  fcntl                                                                           \n","    0.0           46818          13          3601.4            1811            6554  munmap                                                                          \n","    0.0           41627           5          8325.4            4187           13317  open                                                                            \n","    0.0           40654          16          2540.9            1610            4036  fclose                                                                          \n","    0.0           27816          12          2318.0            1307            4182  read                                                                            \n","    0.0           18122           3          6040.7            5448            6639  pipe2                                                                           \n","    0.0           10333           2          5166.5            4313            6020  socket                                                                          \n","    0.0            9000           4          2250.0            2189            2315  mprotect                                                                        \n","    0.0            8136           2          4068.0            3882            4254  fread                                                                           \n","    0.0            7463           1          7463.0            7463            7463  connect                                                                         \n","    0.0            2766           1          2766.0            2766            2766  bind                                                                            \n","    0.0            2107           1          2107.0            2107            2107  listen                                                                          \n","\n","\n","\n","\n","Generating NVTX Push-Pop Range Statistics...\n","NVTX Push-Pop Range Statistics (nanoseconds)\n","\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r1jLxyhe-QYK","colab_type":"text"},"source":["### Optimize Iteratively\n","\n","Several cycles of editing the execution configuration of the code.\n","\n","- Start by listing 3 to 5 different ways you will update the execution configuration, being sure to cover a range of different grid and block size combinations.\n","- Edit the program in one of the ways you listed.\n","- Compile and profile your updated code with the two code execution cells below.\n","- Record the runtime of the kernel execution, as given in the profiling output.\n","- Repeat the edit/profile/record cycle for each possible optimzation you listed above"]},{"cell_type":"code","metadata":{"id":"xOHaqnP5-QYK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e6a65997-244a-4e78-eef4-24173f6c913e","executionInfo":{"status":"ok","timestamp":1591051408739,"user_tz":420,"elapsed":5973,"user":{"displayName":"Gabriele Boncoraglio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXEw7TWB8AnQR7GBopOPG42CBDV3rLZ-UejvU5SA=s64","userId":"05926223390448651175"}}},"source":["!nvcc -o iteratively-optimized-vector-add 01-vector-add.cu -run"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Success! All values calculated correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bjLvESXn-QYO","colab_type":"code","colab":{},"outputId":"6375677a-59d6-4b3d-fd73-fbaf0710ae7c"},"source":["!nsys profile --stats=true ./iteratively-optimized-vector-add"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","**** collection configuration ****\n","\tforce-overwrite = false\n","\tstop-on-exit = true\n","\texport_sqlite = true\n","\tstats = true\n","\tcapture-range = none\n","\tstop-on-range-end = false\n","\tBeta: ftrace events:\n","\tftrace-keep-user-config = false\n","\ttrace-GPU-context-switch = false\n","\tdelay = 0 seconds\n","\tduration = 0 seconds\n","\tkill = signal number 15\n","\tinherit-environment = true\n","\tshow-output = true\n","\ttrace-fork-before-exec = false\n","\tsample_cpu = true\n","\tbacktrace_method = LBR\n","\twait = all\n","\ttrace_cublas = false\n","\ttrace_cuda = true\n","\ttrace_cudnn = false\n","\ttrace_nvtx = true\n","\ttrace_mpi = false\n","\ttrace_openacc = false\n","\ttrace_vulkan = false\n","\ttrace_opengl = true\n","\ttrace_osrt = true\n","\tosrt-threshold = 0 nanoseconds\n","\tcudabacktrace = false\n","\tcudabacktrace-threshold = 0 nanoseconds\n","\tprofile_processes = tree\n","\tapplication command = ./iteratively-optimized-vector-add\n","\tapplication arguments = \n","\tapplication working directory = /dli/task\n","\tNVTX profiler range trigger = \n","\tNVTX profiler domain trigger = \n","\tenvironment variables:\n","\tCollecting data...\n","Success! All values calculated correctly.\n","\tGenerating the /dli/task/report3.qdstrm file.\n","\tCapturing raw events...\n","\t4253 total events collected.\n","\tSaving diagnostics...\n","\tSaving qdstrm file to disk...\n","\tFinished saving file.\n","\n","\n","Importing the qdstrm file using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/QdstrmImporter.\n","\n","Importing...\n","\n","Importing [==================================================100%]\n","Saving report to file \"/dli/task/report3.qdrep\"\n","Report file saved.\n","Please discard the qdstrm file and use the qdrep file instead.\n","\n","Removed /dli/task/report3.qdstrm as it was successfully imported.\n","Please use the qdrep file instead.\n","\n","Exporting the qdrep file to SQLite database using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/nsys-exporter.\n","\n","Exporting 4217 events:\n","\n","0%   10   20   30   40   50   60   70   80   90   100%\n","|----|----|----|----|----|----|----|----|----|----|\n","***************************************************\n","\n","Exported successfully to\n","/dli/task/report3.sqlite\n","\n","Generating CUDA API Statistics...\n","CUDA API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   63.9       246682260           3      82227420.0           27871       246606204  cudaMallocManaged                                                               \n","   29.9       115685415           1     115685415.0       115685415       115685415  cudaDeviceSynchronize                                                           \n","    6.2        23815946           3       7938648.7         7237593         9251174  cudaFree                                                                        \n","    0.0           84905           1         84905.0           84905           84905  cudaLaunchKernel                                                                \n","\n","\n","\n","\n","Generating CUDA Kernel Statistics...\n","\n","Generating CUDA Memory Operation Statistics...\n","CUDA Kernel Statistics (nanoseconds)\n","\n","Time(%)      Total Time   Instances         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","  100.0       115687382           1     115687382.0       115687382       115687382  addVectorsInto                                                                  \n","\n","\n","CUDA Memory Operation Statistics (nanoseconds)\n","\n","Time(%)      Total Time  Operations         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   78.9        42491872        2324         18283.9            2944          117024  [CUDA Unified Memory memcpy HtoD]                                               \n","   21.1        11381600         768         14819.8            1632           85216  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","CUDA Memory Operation Statistics (KiB)\n","\n","            Total      Operations            Average            Minimum            Maximum  Name                                                                            \n","-----------------  --------------  -----------------  -----------------  -----------------  --------------------------------------------------------------------------------\n","         393216.0            2324              169.2              4.000             1000.0  [CUDA Unified Memory memcpy HtoD]                                               \n","         131072.0             768              170.7              4.000             1020.0  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","\n","\n","Generating Operating System Runtime API Statistics...\n","Operating System Runtime API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   55.4      1659765453          85      19526652.4           44523       100185768  poll                                                                            \n","   40.7      1218030277          84      14500360.4           24126       100120018  sem_timedwait                                                                   \n","    3.0        90011124         575        156541.1            1040        20328340  ioctl                                                                           \n","    0.9        26269114          87        301943.8            1735         9196502  mmap                                                                            \n","    0.0          640082          73          8768.2            3763           22618  open64                                                                          \n","    0.0          152336           4         38084.0           36389           39272  pthread_create                                                                  \n","    0.0          145397          23          6321.6            1813           27420  fopen                                                                           \n","    0.0          108748          10         10874.8            7267           15023  write                                                                           \n","    0.0           89140           3         29713.3           21986           43693  fgets                                                                           \n","    0.0           81595          72          1133.3            1011            4948  fcntl                                                                           \n","    0.0           46009          14          3286.4            1835            5196  munmap                                                                          \n","    0.0           41873          16          2617.1            1660            4018  fclose                                                                          \n","    0.0           35967           5          7193.4            4216           12835  open                                                                            \n","    0.0           26639          12          2219.9            1280            3946  read                                                                            \n","    0.0           16521           3          5507.0            5170            5882  pipe2                                                                           \n","    0.0           10420           2          5210.0            4264            6156  socket                                                                          \n","    0.0            8913           4          2228.3            2174            2300  mprotect                                                                        \n","    0.0            7430           2          3715.0            2753            4677  fread                                                                           \n","    0.0            6507           1          6507.0            6507            6507  connect                                                                         \n","    0.0            2506           1          2506.0            2506            2506  bind                                                                            \n","    0.0            1864           1          1864.0            1864            1864  listen                                                                          \n","\n","\n","\n","\r\n","Generating NVTX Push-Pop Range Statistics...\r\n","NVTX Push-Pop Range Statistics (nanoseconds)\r\n","\r\n","\r\n","\r\n","\r\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lsFf7hUI-QYQ","colab_type":"text"},"source":["---\n","## Streaming Multiprocessors and Querying the Device\n","\n","This section explores how understanding a specific feature of the GPU hardware can promote optimization: **Streaming Multiprocessors**. This allows to further optimize the accelerated vector addition program you have been working on.\n"]},{"cell_type":"markdown","metadata":{"id":"azca3k5I-QYU","colab_type":"text"},"source":["### Streaming Multiprocessors and Warps\n","\n","The GPUs that CUDA applications run on have processing units called **streaming multiprocessors**, or **SMs**. During kernel execution, blocks of threads are given to SMs to execute. In order to support the GPU's ability to perform as many parallel operations as possible, performance gains can often be had by *choosing a grid size that has a number of blocks that is a multiple of the number of SMs on a given GPU.*\n","\n","Additionally, SMs create, manage, schedule, and execute groupings of 32 threads from within a block called **warps**. It is important to know that performance gains can also be had by *choosing a block size that has a number of threads that is a multiple of 32.*"]},{"cell_type":"markdown","metadata":{"id":"rXLYpP_e-QYU","colab_type":"text"},"source":["### Programmatically Querying GPU Device Properties\n","\n","In order to support portability, since the number of SMs on a GPU can differ depending on the specific GPU being used, the number of SMs should not be hard-coded into a codebase. Rather, this information should be acquired programatically.\n","\n","The following shows how, in CUDA C/C++, to obtain a C struct which contains many properties about the currently active GPU device, including its number of SMs:\n","\n","```cpp\n","int deviceId;\n","cudaGetDevice(&deviceId);                  // `deviceId` now points to the id of the currently active GPU.\n","\n","cudaDeviceProp props;\n","cudaGetDeviceProperties(&props, deviceId); // `props` now has many useful properties about\n","                                           // the active GPU device.\n","```"]},{"cell_type":"markdown","metadata":{"id":"x00jwhg3-QYV","colab_type":"text"},"source":["### Query the Device\n","\n","\n","Code to print the actual values for the desired device properties indicated in the source code. It is helpful to use the [CUDA Runtime Docs](http://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html) to help identify the relevant properties in the device props struct."]},{"cell_type":"code","metadata":{"id":"mco4UBHb-QYV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"b78c61c6-7502-44a5-ac5c-064a5286aa26","executionInfo":{"status":"ok","timestamp":1591051556362,"user_tz":420,"elapsed":1902,"user":{"displayName":"Gabriele Boncoraglio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXEw7TWB8AnQR7GBopOPG42CBDV3rLZ-UejvU5SA=s64","userId":"05926223390448651175"}}},"source":["!nvcc -o get-device-properties 01-get-device-properties.cu -run"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Device ID: 0\n","Number of SMs: 56\n","Compute Capability Major: 6\n","Compute Capability Minor: 0\n","Warp Size: 32\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oAZ2ihY_-QYX","colab_type":"text"},"source":["### Optimize Vector Add with Grids Sized to Number of SMs\n","\n","Using the ability to query the device for its number of SMs to refactor the `addVectorsInto` kernel so that it launches with a grid containing a number of blocks that is a multiple of the number of SMs on the device.\n","\n","Depending on other specific details in the code you have written, this refactor may or may not improve, or significantly change, the performance of your kernel. Therefore, as always, better to use `nsys profile` so that we can quantitatively evaulate performance changes. "]},{"cell_type":"code","metadata":{"id":"_vB9nTaL-QYY","colab_type":"code","colab":{},"outputId":"ee5fe826-111a-48e1-ebc1-69e821e0974c"},"source":["!nvcc -o sm-optimized-vector-add 01-vector-add/01-vector-add.cu -run"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Success! All values calculated correctly.\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MdB5Bee4-QYb","colab_type":"code","colab":{},"outputId":"7827f492-78f3-4b65-c8cd-7d1b90554581"},"source":["!nsys profile --stats=true ./sm-optimized-vector-add"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","**** collection configuration ****\n","\tforce-overwrite = false\n","\tstop-on-exit = true\n","\texport_sqlite = true\n","\tstats = true\n","\tcapture-range = none\n","\tstop-on-range-end = false\n","\tBeta: ftrace events:\n","\tftrace-keep-user-config = false\n","\ttrace-GPU-context-switch = false\n","\tdelay = 0 seconds\n","\tduration = 0 seconds\n","\tkill = signal number 15\n","\tinherit-environment = true\n","\tshow-output = true\n","\ttrace-fork-before-exec = false\n","\tsample_cpu = true\n","\tbacktrace_method = LBR\n","\twait = all\n","\ttrace_cublas = false\n","\ttrace_cuda = true\n","\ttrace_cudnn = false\n","\ttrace_nvtx = true\n","\ttrace_mpi = false\n","\ttrace_openacc = false\n","\ttrace_vulkan = false\n","\ttrace_opengl = true\n","\ttrace_osrt = true\n","\tosrt-threshold = 0 nanoseconds\n","\tcudabacktrace = false\n","\tcudabacktrace-threshold = 0 nanoseconds\n","\tprofile_processes = tree\n","\tapplication command = ./sm-optimized-vector-add\n","\tapplication arguments = \n","\tapplication working directory = /dli/task\n","\tNVTX profiler range trigger = \n","\tNVTX profiler domain trigger = \n","\tenvironment variables:\n","\tCollecting data...\n","Success! All values calculated correctly.\n","\tGenerating the /dli/task/report4.qdstrm file.\n","\tCapturing raw events...\n","\t5999 total events collected.\n","\tSaving diagnostics...\n","\tSaving qdstrm file to disk...\n","\tFinished saving file.\n","\n","\n","Importing the qdstrm file using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/QdstrmImporter.\n","\n","Importing...\n","\n","Importing [==================================================100%]\n","Saving report to file \"/dli/task/report4.qdrep\"\n","Report file saved.\n","Please discard the qdstrm file and use the qdrep file instead.\n","\n","Removed /dli/task/report4.qdstrm as it was successfully imported.\n","Please use the qdrep file instead.\n","\n","Exporting the qdrep file to SQLite database using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/nsys-exporter.\n","\n","Exporting 5960 events:\n","\n","0%   10   20   30   40   50   60   70   80   90   100%\n","|----|----|----|----|----|----|----|----|----|----|\n","***************************************************\n","\n","Exported successfully to\n","/dli/task/report4.sqlite\n","\n","Generating CUDA API Statistics...\n","CUDA API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   63.1       244404246           3      81468082.0           28138       244327768  cudaMallocManaged                                                               \n","   30.8       119508284           1     119508284.0       119508284       119508284  cudaDeviceSynchronize                                                           \n","    6.0        23408984           3       7802994.7         7074335         9119614  cudaFree                                                                        \n","    0.0          179427           1        179427.0          179427          179427  cudaLaunchKernel                                                                \n","\n","\n","\n","\n","Generating CUDA Kernel Statistics...\n","\n","Generating CUDA Memory Operation Statistics...\n","CUDA Kernel Statistics (nanoseconds)\n","\n","Time(%)      Total Time   Instances         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","  100.0       119609475           1     119609475.0       119609475       119609475  addVectorsInto                                                                  \n","\n","\n","CUDA Memory Operation Statistics (nanoseconds)\n","\n","Time(%)      Total Time  Operations         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   80.6        47065408        4066         11575.4            2048          111936  [CUDA Unified Memory memcpy HtoD]                                               \n","   19.4        11358880         768         14790.2            1888           91488  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","CUDA Memory Operation Statistics (KiB)\n","\n","            Total      Operations            Average            Minimum            Maximum  Name                                                                            \n","-----------------  --------------  -----------------  -----------------  -----------------  --------------------------------------------------------------------------------\n","         393216.0            4066               96.7              4.000             1020.0  [CUDA Unified Memory memcpy HtoD]                                               \n","         131072.0             768              170.7              4.000             1020.0  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","\n","\n","Generating Operating System Runtime API Statistics...\n","Operating System Runtime API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   55.4      1661278098          86      19317187.2           44713       100189851  poll                                                                            \n","   40.7      1222049044          86      14209872.6           23969       100130034  sem_timedwait                                                                   \n","    3.0        88670627         576        153942.1            1037        20129573  ioctl                                                                           \n","    0.9        25871826          87        297377.3            1686         9063906  mmap                                                                            \n","    0.0          644232          73          8825.1            3834           21780  open64                                                                          \n","    0.0          152206           4         38051.5           31554           44398  pthread_create                                                                  \n","    0.0          126051          23          5480.5            1809           14285  fopen                                                                           \n","    0.0          111553          10         11155.3            7533           16063  write                                                                           \n","    0.0           91184           3         30394.7           23183           43817  fgets                                                                           \n","    0.0           79441          70          1134.9            1010            5274  fcntl                                                                           \n","    0.0           45436          13          3495.1            1726            6528  munmap                                                                          \n","    0.0           40970          16          2560.6            1561            3943  fclose                                                                          \n","    0.0           34394           5          6878.8            4123           11340  open                                                                            \n","    0.0           27081          12          2256.8            1247            6036  read                                                                            \n","    0.0           17011           3          5670.3            4802            6243  pipe2                                                                           \n","    0.0           11781           2          5890.5            4760            7021  socket                                                                          \n","    0.0            8873           4          2218.3            2168            2257  mprotect                                                                        \n","    0.0            7316           2          3658.0            2853            4463  fread                                                                           \n","    0.0            6878           1          6878.0            6878            6878  connect                                                                         \n","    0.0            2560           1          2560.0            2560            2560  bind                                                                            \n","    0.0            1800           1          1800.0            1800            1800  listen                                                                          \n","\n","\n","\n","\n","Generating NVTX Push-Pop Range Statistics...\n","NVTX Push-Pop Range Statistics (nanoseconds)\n","\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WtC8byrq-QYd","colab_type":"text"},"source":["---\n","## Unified Memory Details\n","\n","You have been allocting memory intended for use either by host or device code with `cudaMallocManaged` and up until now have enjoyed the benefits of this method - automatic memory migration, ease of programming - without diving into the details of how the **Unified Memory** (**UM**) allocated by `cudaMallocManaged` actual works.\n","\n","`nsys profile` provides details about UM management in accelerated applications, and using this information, in conjunction with a more-detailed understanding of how UM works, provides additional opportunities to optimize accelerated applications."]},{"cell_type":"markdown","metadata":{"id":"HVjCZMfY-QYf","colab_type":"text"},"source":["### Unified Memory Migration\n","\n","When UM is allocated, the memory is not resident yet on either the host or the device. When either the host or device attempts to access the memory, a [page fault](https://en.wikipedia.org/wiki/Page_fault) will occur, at which point the host or device will migrate the needed data in batches. Similarly, at any point when the CPU, or any GPU in the accelerated system, attempts to access memory not yet resident on it, page faults will occur and trigger its migration.\n","\n","The ability to page fault and migrate memory on demand is tremendously helpful for ease of development in your accelerated applications. Additionally, when working with data that exhibits sparse access patterns, for example when it is impossible to know which data will be required to be worked on until the application actually runs, and for scenarios when data might be accessed by multiple GPU devices in an accelerated system with multiple GPUs, on-demand memory migration is remarkably beneficial.\n","\n","There are times - for example when data needs are known prior to runtime, and large contiguous blocks of memory are required - when the overhead of page faulting and migrating data on demand incurs an overhead cost that would be better avoided.\n"]},{"cell_type":"markdown","metadata":{"id":"b4hwQ3iY-QYg","colab_type":"text"},"source":["### Explore UM Migration and Page Faulting"]},{"cell_type":"markdown","metadata":{"id":"HQSpYmit-QYg","colab_type":"text"},"source":["`nsys profile` provides output describing UM behavior for the profiled application. \n","\n","\n","- Is there a _CUDA Memory Operation Statistics_ section in the output?\n","- If so, does it indicate host to device (HtoD) or device to host (DtoH) migrations?\n","- When there are migrations, what does the output say about how many _Operations_ there were? If you see many small memory migration operations, this is a sign that on-demand page faulting is occuring, with small memory migrations occuring each time there is a page fault in the requested location."]},{"cell_type":"markdown","metadata":{"id":"yojrnQCh-QYh","colab_type":"text"},"source":["Here are the scenarios for you to explore, along with solutions for them if you get stuck:\n","\n","- Is there evidence of memory migration and/or page faulting when unified memory is accessed only by the CPU? ([solution](../edit/06-unified-memory-page-faults/solutions/01-page-faults-solution-cpu-only.cu))\n","- Is there evidence of memory migration and/or page faulting when unified memory is accessed only by the GPU? ([solution](../edit/06-unified-memory-page-faults/solutions/02-page-faults-solution-gpu-only.cu))\n","- Is there evidence of memory migration and/or page faulting when unified memory is accessed first by the CPU then the GPU? ([solution](../edit/06-unified-memory-page-faults/solutions/03-page-faults-solution-cpu-then-gpu.cu))\n","- Is there evidence of memory migration and/or page faulting when unified memory is accessed first by the GPU then the CPU? ([solution](../edit/06-unified-memory-page-faults/solutions/04-page-faults-solution-gpu-then-cpu.cu))"]},{"cell_type":"code","metadata":{"id":"8s0cjsv6-QYh","colab_type":"code","colab":{}},"source":["!nvcc -o page-faults 01-page-faults-cpu-only.cu -run"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXIcgUVjF-Wv","colab_type":"code","colab":{}},"source":["!nvcc -o page-faults 02-page-faults-gpu-only.cu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u9_SjBx3GM05","colab_type":"code","colab":{}},"source":["!nvcc -o page-faults 03-page-faults-cpu-then-gpu.cu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M8emCslMGPu-","colab_type":"code","colab":{}},"source":["!nvcc -o page-faults 04-page-faults-gpu-then-cpu.cu"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6grDm6tm-QYk","colab_type":"code","colab":{}},"source":["!nsys profile --stats=true ./page-faults"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PPu8oKlg-QYn","colab_type":"text"},"source":["### Revisit UM Behavior for Vector Add Program\n","\n","Returning to the program we have been working addVector, review the codebase in its current state, and hypothesize about what kinds of memory migrations and/or page faults you expect to occur. Look the _CUDA Memory Operation Statistics_ section of the profiler output."]},{"cell_type":"code","metadata":{"id":"bk00H5Yv-QYn","colab_type":"code","colab":{},"outputId":"2143a4d7-7f03-4055-ecd7-30f28427e4e4"},"source":["!nsys profile --stats=true ./sm-optimized-vector-add"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","**** collection configuration ****\n","\tforce-overwrite = false\n","\tstop-on-exit = true\n","\texport_sqlite = true\n","\tstats = true\n","\tcapture-range = none\n","\tstop-on-range-end = false\n","\tBeta: ftrace events:\n","\tftrace-keep-user-config = false\n","\ttrace-GPU-context-switch = false\n","\tdelay = 0 seconds\n","\tduration = 0 seconds\n","\tkill = signal number 15\n","\tinherit-environment = true\n","\tshow-output = true\n","\ttrace-fork-before-exec = false\n","\tsample_cpu = true\n","\tbacktrace_method = LBR\n","\twait = all\n","\ttrace_cublas = false\n","\ttrace_cuda = true\n","\ttrace_cudnn = false\n","\ttrace_nvtx = true\n","\ttrace_mpi = false\n","\ttrace_openacc = false\n","\ttrace_vulkan = false\n","\ttrace_opengl = true\n","\ttrace_osrt = true\n","\tosrt-threshold = 0 nanoseconds\n","\tcudabacktrace = false\n","\tcudabacktrace-threshold = 0 nanoseconds\n","\tprofile_processes = tree\n","\tapplication command = ./sm-optimized-vector-add\n","\tapplication arguments = \n","\tapplication working directory = /dli/task\n","\tNVTX profiler range trigger = \n","\tNVTX profiler domain trigger = \n","\tenvironment variables:\n","\tCollecting data...\n","Success! All values calculated correctly.\n","\tGenerating the /dli/task/report5.qdstrm file.\n","\tCapturing raw events...\n","\t5928 total events collected.\n","\tSaving diagnostics...\n","\tSaving qdstrm file to disk...\n","\tFinished saving file.\n","\n","\n","Importing the qdstrm file using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/QdstrmImporter.\n","\n","Importing...\n","\n","Importing [==================================================100%]\n","Saving report to file \"/dli/task/report5.qdrep\"\n","Report file saved.\n","Please discard the qdstrm file and use the qdrep file instead.\n","\n","Removed /dli/task/report5.qdstrm as it was successfully imported.\n","Please use the qdrep file instead.\n","\n","Exporting the qdrep file to SQLite database using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/nsys-exporter.\n","\n","Exporting 5892 events:\n","\n","0%   10   20   30   40   50   60   70   80   90   100%\n","|----|----|----|----|----|----|----|----|----|----|\n","***************************************************\n","\n","Exported successfully to\n","/dli/task/report5.sqlite\n","\n","Generating CUDA API Statistics...\n","CUDA API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   63.1       251519160           3      83839720.0           27642       251440515  cudaMallocManaged                                                               \n","   30.8       122717874           1     122717874.0       122717874       122717874  cudaDeviceSynchronize                                                           \n","    6.0        24057980           3       8019326.7         7338224         9271048  cudaFree                                                                        \n","    0.0           83093           1         83093.0           83093           83093  cudaLaunchKernel                                                                \n","\n","\n","\n","\n","Generating CUDA Kernel Statistics...\n","\n","Generating CUDA Memory Operation Statistics...\n","CUDA Kernel Statistics (nanoseconds)\n","\n","Time(%)      Total Time   Instances         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","  100.0       122719205           1     122719205.0       122719205       122719205  addVectorsInto                                                                  \n","\n","\n","CUDA Memory Operation Statistics (nanoseconds)\n","\n","Time(%)      Total Time  Operations         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   80.5        47054464        3991         11790.1            2816          113824  [CUDA Unified Memory memcpy HtoD]                                               \n","   19.5        11412416         768         14859.9            1856           86016  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","CUDA Memory Operation Statistics (KiB)\n","\n","            Total      Operations            Average            Minimum            Maximum  Name                                                                            \n","-----------------  --------------  -----------------  -----------------  -----------------  --------------------------------------------------------------------------------\n","         393216.0            3991               98.5              4.000             1020.0  [CUDA Unified Memory memcpy HtoD]                                               \n","         131072.0             768              170.7              4.000             1020.0  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","\n","\n","Generating Operating System Runtime API Statistics...\n","Operating System Runtime API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   54.9      1680381557          88      19095245.0            1827       100195341  poll                                                                            \n","   41.2      1262321077          88      14344557.7            1464       100134032  sem_timedwait                                                                   \n","    3.0        92736604         576        161001.0            1046        20841130  ioctl                                                                           \n","    0.9        26556102          87        305242.6            1703         9213177  mmap                                                                            \n","    0.0          703883          73          9642.2            3925           21638  open64                                                                          \n","    0.0          161336           4         40334.0           36637           48318  pthread_create                                                                  \n","    0.0          130627          23          5679.4            1961           15394  fopen                                                                           \n","    0.0          116065          10         11606.5            8024           16028  write                                                                           \n","    0.0           90916           3         30305.3           22073           43991  fgets                                                                           \n","    0.0           81783          72          1135.9            1000            5221  fcntl                                                                           \n","    0.0           63768           5         12753.6            5303           29240  open                                                                            \n","    0.0           48924          14          3494.6            1618            5839  munmap                                                                          \n","    0.0           43599          16          2724.9            1634            4097  fclose                                                                          \n","    0.0           28173          12          2347.7            1329            5701  read                                                                            \n","    0.0           17838           3          5946.0            4658            6731  pipe2                                                                           \n","    0.0           11311           2          5655.5            4483            6828  socket                                                                          \n","    0.0           10021           4          2505.3            2251            2899  mprotect                                                                        \n","    0.0            7702           2          3851.0            3029            4673  fread                                                                           \n","    0.0            7158           1          7158.0            7158            7158  connect                                                                         \n","    0.0            2917           1          2917.0            2917            2917  bind                                                                            \n","    0.0            1933           1          1933.0            1933            1933  listen                                                                          \n","\n","\n","\n","\r\n","Generating NVTX Push-Pop Range Statistics...\r\n","NVTX Push-Pop Range Statistics (nanoseconds)\r\n","\r\n","\r\n","\r\n","\r\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m5m5tpQK-QYp","colab_type":"text"},"source":["### Initialize Vector in Kernel\n","\n","When `nsys profile` gives the amount of time that a kernel takes to execute, the host-to-device page faults and data migrations that occur during this kernel's execution are included in the displayed execution time.\n","\n","With this in mind, refactor the `initWith` host function in your [01-vector-add.cu] program to instead be a CUDA kernel, initializing the allocated vector in parallel on the GPU. "]},{"cell_type":"code","metadata":{"id":"On4X6v2c-QYq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"fc5323ed-44fd-4e4a-80d9-a0bcec86af25","executionInfo":{"status":"ok","timestamp":1591052441107,"user_tz":420,"elapsed":2013,"user":{"displayName":"Gabriele Boncoraglio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXEw7TWB8AnQR7GBopOPG42CBDV3rLZ-UejvU5SA=s64","userId":"05926223390448651175"}}},"source":["!nvcc -o initialize-in-kernel 01-vector-add-init-in-kernel.cu -run"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Device ID: 0\tNumber of SMs: 56\n","Success! All values calculated correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3H0FKXou-QYs","colab_type":"code","colab":{},"outputId":"de844eb0-43f1-4990-b5d6-a09b21f9ab65"},"source":["#Execution time much faster since data migration is only Device to Host \n","!nsys profile --stats=true ./initialize-in-kernel"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","**** collection configuration ****\n","\tforce-overwrite = false\n","\tstop-on-exit = true\n","\texport_sqlite = true\n","\tstats = true\n","\tcapture-range = none\n","\tstop-on-range-end = false\n","\tBeta: ftrace events:\n","\tftrace-keep-user-config = false\n","\ttrace-GPU-context-switch = false\n","\tdelay = 0 seconds\n","\tduration = 0 seconds\n","\tkill = signal number 15\n","\tinherit-environment = true\n","\tshow-output = true\n","\ttrace-fork-before-exec = false\n","\tsample_cpu = true\n","\tbacktrace_method = LBR\n","\twait = all\n","\ttrace_cublas = false\n","\ttrace_cuda = true\n","\ttrace_cudnn = false\n","\ttrace_nvtx = true\n","\ttrace_mpi = false\n","\ttrace_openacc = false\n","\ttrace_vulkan = false\n","\ttrace_opengl = true\n","\ttrace_osrt = true\n","\tosrt-threshold = 0 nanoseconds\n","\tcudabacktrace = false\n","\tcudabacktrace-threshold = 0 nanoseconds\n","\tprofile_processes = tree\n","\tapplication command = ./initialize-in-kernel\n","\tapplication arguments = \n","\tapplication working directory = /dli/task\n","\tNVTX profiler range trigger = \n","\tNVTX profiler domain trigger = \n","\tenvironment variables:\n","\tCollecting data...\n","Device ID: 0\tNumber of SMs: 80\n","Success! All values calculated correctly.\n","\tGenerating the /dli/task/report6.qdstrm file.\n","\tCapturing raw events...\n","\t1837 total events collected.\n","\tSaving diagnostics...\n","\tSaving qdstrm file to disk...\n","\tFinished saving file.\n","\n","\n","Importing the qdstrm file using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/QdstrmImporter.\n","\n","Importing...\n","\n","Importing [==================================================100%]\n","Saving report to file \"/dli/task/report6.qdrep\"\n","Report file saved.\n","Please discard the qdstrm file and use the qdrep file instead.\n","\n","Removed /dli/task/report6.qdstrm as it was successfully imported.\n","Please use the qdrep file instead.\n","\n","Exporting the qdrep file to SQLite database using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/nsys-exporter.\n","\n","Exporting 1800 events:\n","\n","0%   10   20   30   40   50   60   70   80   90   100%\n","|----|----|----|----|----|----|----|----|----|----|\n","***************************************************\n","\n","Exported successfully to\n","/dli/task/report6.sqlite\n","\n","Generating CUDA API Statistics...\n","CUDA API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   79.1       244936233           3      81645411.0           27685       244861630  cudaMallocManaged                                                               \n","   14.2        44030348           2      22015174.0          510493        43519855  cudaDeviceSynchronize                                                           \n","    6.6        20521095           3       6840365.0         5763057         8901743  cudaFree                                                                        \n","    0.1          180316           4         45079.0           12157          103468  cudaLaunchKernel                                                                \n","\n","\n","\n","\n","Generating CUDA Kernel Statistics...\n","\n","Generating CUDA Memory Operation Statistics...\n","CUDA Kernel Statistics (nanoseconds)\n","\n","Time(%)      Total Time   Instances         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   98.8        43631211           3      14543737.0        14236313        14794565  initWith                                                                        \n","    1.2          509167           1        509167.0          509167          509167  addArraysInto                                                                   \n","\n","\n","CUDA Memory Operation Statistics (nanoseconds)\n","\n","Time(%)      Total Time  Operations         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","  100.0        11450528         768         14909.5            1984           92832  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","CUDA Memory Operation Statistics (KiB)\n","\n","            Total      Operations            Average            Minimum            Maximum  Name                                                                            \n","-----------------  --------------  -----------------  -----------------  -----------------  --------------------------------------------------------------------------------\n","         131072.0             768              170.7              4.000             1020.0  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","\n","\n","Generating Operating System Runtime API Statistics...\n","Operating System Runtime API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   46.9       602749166          34      17727916.6           47194       100178925  poll                                                                            \n","   44.2       567856270          33      17207765.8           25048       100119311  sem_timedwait                                                                   \n","    6.9        89227996         576        154909.7            1067        20098583  ioctl                                                                           \n","    1.8        23020213          87        264600.1            1615         8845752  mmap                                                                            \n","    0.1          657816          73          9011.2            3973           22204  open64                                                                          \n","    0.0          149105           4         37276.3           33789           41308  pthread_create                                                                  \n","    0.0          124220          23          5400.9            1839           13820  fopen                                                                           \n","    0.0          107570          10         10757.0            7672           13980  write                                                                           \n","    0.0           90140           3         30046.7           21415           44275  fgets                                                                           \n","    0.0           80325          71          1131.3            1002            4828  fcntl                                                                           \n","    0.0           46822          14          3344.4            1769            5801  munmap                                                                          \n","    0.0           41248          16          2578.0            1610            3949  fclose                                                                          \n","    0.0           34302           5          6860.4            4340           10560  open                                                                            \n","    0.0           26493          12          2207.8            1270            3991  read                                                                            \n","    0.0           18495           3          6165.0            5047            7379  pipe2                                                                           \n","    0.0           10899           2          5449.5            4751            6148  socket                                                                          \n","    0.0           10094           3          3364.7            2413            4902  fread                                                                           \n","    0.0            8649           4          2162.3            2109            2232  mprotect                                                                        \n","    0.0            7051           1          7051.0            7051            7051  connect                                                                         \n","    0.0            3175           1          3175.0            3175            3175  bind                                                                            \n","    0.0            1857           1          1857.0            1857            1857  listen                                                                          \n","\n","\n","\n","\r\n","Generating NVTX Push-Pop Range Statistics...\r\n","NVTX Push-Pop Range Statistics (nanoseconds)\r\n","\r\n","\r\n","\r\n","\r\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n6KxmW9--QYu","colab_type":"text"},"source":["---\n","## Asynchronous Memory Prefetching\n","\n","A powerful technique to reduce the overhead of page faulting and on-demand memory migrations, both in host-to-device and device-to-host memory transfers, is called **asynchronous memory prefetching**. Using this technique allows programmers to asynchronously migrate unified memory (UM) to any CPU or GPU device in the system, in the background, prior to its use by application code. By doing this, GPU kernels and CPU function performance can be increased on account of reduced page fault and on-demand data migration overhead.\n","\n","Prefetching also tends to migrate data in larger chunks, and therefore fewer trips, than on-demand migration. This makes it an excellent fit when data access needs are known before runtime, and when data access patterns are not sparse.\n","\n","CUDA Makes asynchronously prefetching managed memory to either a GPU device or the CPU easy with its `cudaMemPrefetchAsync` function. Here is an example of using it to both prefetch data to the currently active GPU device, and then, to the CPU:\n","\n","```cpp\n","int deviceId;\n","cudaGetDevice(&deviceId);                                         // The ID of the currently active GPU device.\n","\n","cudaMemPrefetchAsync(pointerToSomeUMData, size, deviceId);        // Prefetch to GPU device.\n","cudaMemPrefetchAsync(pointerToSomeUMData, size, cudaCpuDeviceId); // Prefetch to host. `cudaCpuDeviceId` is a\n","                                                                  // built-in CUDA variable.\n","```"]},{"cell_type":"markdown","metadata":{"id":"aBhNjELB-QYu","colab_type":"text"},"source":["### Prefetch Memory\n","\n","\n","Conduct 3 experiments using `cudaMemPrefetchAsync` inside of your [01-vector-add.cu] application to understand its impact on page-faulting and memory migration.\n","\n","- What happens when you prefetch one of the initialized vectors to the device?\n","- What happens when you prefetch two of the initialized vectors to the device?\n","- What happens when you prefetch all three of the initialized vectors to the device?\n"]},{"cell_type":"code","metadata":{"id":"oNev8TDT-QYv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"cc2840d7-9e1b-4bbb-9543-a59346512850","executionInfo":{"status":"ok","timestamp":1591052705967,"user_tz":420,"elapsed":2274,"user":{"displayName":"Gabriele Boncoraglio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXEw7TWB8AnQR7GBopOPG42CBDV3rLZ-UejvU5SA=s64","userId":"05926223390448651175"}}},"source":["!nvcc -o prefetch-to-gpu 01-vector-add-prefetch.cu -run"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Device ID: 0\tNumber of SMs: 56\n","Success! All values calculated correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RRWxpiYL-QYx","colab_type":"code","colab":{},"outputId":"5ac042a2-211e-4470-ea3a-a87f70aa41f3"},"source":["!nsys profile --stats=true ./prefetch-to-gpu"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","**** collection configuration ****\n","\tforce-overwrite = false\n","\tstop-on-exit = true\n","\texport_sqlite = true\n","\tstats = true\n","\tcapture-range = none\n","\tstop-on-range-end = false\n","\tBeta: ftrace events:\n","\tftrace-keep-user-config = false\n","\ttrace-GPU-context-switch = false\n","\tdelay = 0 seconds\n","\tduration = 0 seconds\n","\tkill = signal number 15\n","\tinherit-environment = true\n","\tshow-output = true\n","\ttrace-fork-before-exec = false\n","\tsample_cpu = true\n","\tbacktrace_method = LBR\n","\twait = all\n","\ttrace_cublas = false\n","\ttrace_cuda = true\n","\ttrace_cudnn = false\n","\ttrace_nvtx = true\n","\ttrace_mpi = false\n","\ttrace_openacc = false\n","\ttrace_vulkan = false\n","\ttrace_opengl = true\n","\ttrace_osrt = true\n","\tosrt-threshold = 0 nanoseconds\n","\tcudabacktrace = false\n","\tcudabacktrace-threshold = 0 nanoseconds\n","\tprofile_processes = tree\n","\tapplication command = ./prefetch-to-gpu\n","\tapplication arguments = \n","\tapplication working directory = /dli/task\n","\tNVTX profiler range trigger = \n","\tNVTX profiler domain trigger = \n","\tenvironment variables:\n","\tCollecting data...\n","Device ID: 0\tNumber of SMs: 80\n","Success! All values calculated correctly.\n","\tGenerating the /dli/task/report7.qdstrm file.\n","\tCapturing raw events...\n","\t2132 total events collected.\n","\tSaving diagnostics...\n","\tSaving qdstrm file to disk...\n","\tFinished saving file.\n","\n","\n","Importing the qdstrm file using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/QdstrmImporter.\n","\n","Importing...\n","\n","Importing [==================================================100%]\n","Saving report to file \"/dli/task/report7.qdrep\"\n","Report file saved.\n","Please discard the qdstrm file and use the qdrep file instead.\n","\n","Removed /dli/task/report7.qdstrm as it was successfully imported.\n","Please use the qdrep file instead.\n","\n","Exporting the qdrep file to SQLite database using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/nsys-exporter.\n","\n","Exporting 2095 events:\n","\n","0%   10   20   30   40   50   60   70   80   90   100%\n","|----|----|----|----|----|----|----|----|----|----|\n","***************************************************\n","\n","Exported successfully to\n","/dli/task/report7.sqlite\n","\n","Generating CUDA API Statistics...\n","CUDA API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   79.6       251717241           3      83905747.0           27424       251640146  cudaMallocManaged                                                               \n","    9.7        30664979           1      30664979.0        30664979        30664979  cudaDeviceSynchronize                                                           \n","    7.4        23270487           3       7756829.0         6938703         9131867  cudaFree                                                                        \n","    3.3        10488962           3       3496320.7           11052        10283610  cudaMemPrefetchAsync                                                            \n","    0.0           63478           1         63478.0           63478           63478  cudaLaunchKernel                                                                \n","\n","\n","\n","\n","Generating CUDA Kernel Statistics...\n","\n","Generating CUDA Memory Operation Statistics...\n","CUDA Kernel Statistics (nanoseconds)\n","\n","Time(%)      Total Time   Instances         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","  100.0          516992           1        516992.0          516992          516992  addVectorsInto                                                                  \n","\n","\n","CUDA Memory Operation Statistics (nanoseconds)\n","\n","Time(%)      Total Time  Operations         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   76.5        37216352         192        193835.2          192544          217152  [CUDA Unified Memory memcpy HtoD]                                               \n","   23.5        11435392         768         14889.8            1952           91456  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","CUDA Memory Operation Statistics (KiB)\n","\n","            Total      Operations            Average            Minimum            Maximum  Name                                                                            \n","-----------------  --------------  -----------------  -----------------  -----------------  --------------------------------------------------------------------------------\n","         393216.0             192             2048.0           2048.000             2048.0  [CUDA Unified Memory memcpy HtoD]                                               \n","         131072.0             768              170.7              4.000             1020.0  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","\n","\n","Generating Operating System Runtime API Statistics...\n","Operating System Runtime API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   53.7      1498487802          82      18274241.5           46383       100188101  poll                                                                            \n","   40.7      1134456784          78      14544317.7           24004       100134451  sem_timedwait                                                                   \n","    4.5       126575092         579        218609.8            1039        20733532  ioctl                                                                           \n","    0.9        25891295          88        294219.3            1710         9074679  mmap                                                                            \n","    0.1         3476694           3       1158898.0           35796         3217984  sem_wait                                                                        \n","    0.0          710151          73          9728.1            3697           24359  open64                                                                          \n","    0.0          249879           5         49975.8           37711           90554  pthread_create                                                                  \n","    0.0          141766          12         11813.8            7764           17548  write                                                                           \n","    0.0          129978          23          5651.2            1877           15210  fopen                                                                           \n","    0.0           92568           3         30856.0           23072           44686  fgets                                                                           \n","    0.0           83251          73          1140.4            1000            5064  fcntl                                                                           \n","    0.0           47985          14          3427.5            1880            5935  munmap                                                                          \n","    0.0           42690          16          2668.1            1572            4128  fclose                                                                          \n","    0.0           37180           5          7436.0            4054           12648  open                                                                            \n","    0.0           32351          14          2310.8            1285            4416  read                                                                            \n","    0.0           17929           3          5976.3            5102            6792  pipe2                                                                           \n","    0.0           13142           5          2628.4            2321            3736  mprotect                                                                        \n","    0.0           11151           2          5575.5            4799            6352  socket                                                                          \n","    0.0            7915           2          3957.5            3394            4521  fread                                                                           \n","    0.0            7221           1          7221.0            7221            7221  connect                                                                         \n","    0.0            2720           1          2720.0            2720            2720  bind                                                                            \n","    0.0            2039           1          2039.0            2039            2039  listen                                                                          \n","    0.0            1008           1          1008.0            1008            1008  pthread_cond_broadcast                                                          \n","\n","\n","\n","\r\n","Generating NVTX Push-Pop Range Statistics...\r\n","NVTX Push-Pop Range Statistics (nanoseconds)\r\n","\r\n","\r\n","\r\n","\r\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KSQNDS4Z-QYz","colab_type":"text"},"source":["### Prefetch Memory Back to the CPU\n","\n","Add additional prefetching back to the CPU for the function that verifies the correctness of the `addVectorInto` kernel."]},{"cell_type":"code","metadata":{"id":"Tl0WaXLC-QYz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"1d0d8310-f040-4d12-92f8-bf50b24308b1","executionInfo":{"status":"ok","timestamp":1591052848297,"user_tz":420,"elapsed":2372,"user":{"displayName":"Gabriele Boncoraglio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXEw7TWB8AnQR7GBopOPG42CBDV3rLZ-UejvU5SA=s64","userId":"05926223390448651175"}}},"source":["!nvcc -o prefetch-to-cpu 02-vector-add-prefetch-cpu-also.cu -run"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Device ID: 0\tNumber of SMs: 56\n","Success! All values calculated correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nbxzP2lW-QY1","colab_type":"code","colab":{},"outputId":"06ac110e-a114-4768-f129-5f6f9eefc4c7"},"source":["!nsys profile --stats=true ./prefetch-to-cpu"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","**** collection configuration ****\n","\tforce-overwrite = false\n","\tstop-on-exit = true\n","\texport_sqlite = true\n","\tstats = true\n","\tcapture-range = none\n","\tstop-on-range-end = false\n","\tBeta: ftrace events:\n","\tftrace-keep-user-config = false\n","\ttrace-GPU-context-switch = false\n","\tdelay = 0 seconds\n","\tduration = 0 seconds\n","\tkill = signal number 15\n","\tinherit-environment = true\n","\tshow-output = true\n","\ttrace-fork-before-exec = false\n","\tsample_cpu = true\n","\tbacktrace_method = LBR\n","\twait = all\n","\ttrace_cublas = false\n","\ttrace_cuda = true\n","\ttrace_cudnn = false\n","\ttrace_nvtx = true\n","\ttrace_mpi = false\n","\ttrace_openacc = false\n","\ttrace_vulkan = false\n","\ttrace_opengl = true\n","\ttrace_osrt = true\n","\tosrt-threshold = 0 nanoseconds\n","\tcudabacktrace = false\n","\tcudabacktrace-threshold = 0 nanoseconds\n","\tprofile_processes = tree\n","\tapplication command = ./prefetch-to-cpu\n","\tapplication arguments = \n","\tapplication working directory = /dli/task\n","\tNVTX profiler range trigger = \n","\tNVTX profiler domain trigger = \n","\tenvironment variables:\n","\tCollecting data...\n","Device ID: 0\tNumber of SMs: 80\n","Success! All values calculated correctly.\n","\tGenerating the /dli/task/report8.qdstrm file.\n","\tCapturing raw events...\n","\t1415 total events collected.\n","\tSaving diagnostics...\n","\tSaving qdstrm file to disk...\n","\tFinished saving file.\n","\n","\n","Importing the qdstrm file using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/QdstrmImporter.\n","\n","Importing...\n","\n","Importing [==================================================100%]\n","Saving report to file \"/dli/task/report8.qdrep\"\n","Report file saved.\n","Please discard the qdstrm file and use the qdrep file instead.\n","\n","Removed /dli/task/report8.qdstrm as it was successfully imported.\n","Please use the qdrep file instead.\n","\n","Exporting the qdrep file to SQLite database using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/nsys-exporter.\n","\n","Exporting 1379 events:\n","\n","0%   10   20   30   40   50   60   70   80   90   100%\n","|----|----|----|----|----|----|----|----|----|----|\n","***************************************************\n","\n","Exported successfully to\n","/dli/task/report8.sqlite\n","\n","Generating CUDA API Statistics...\n","CUDA API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   51.6       246909335           3      82303111.7           28770       246832866  cudaMallocManaged                                                               \n","   37.0       176803038           7      25257576.9           10805        52571163  cudaMemPrefetchAsync                                                            \n","    6.4        30846432           1      30846432.0        30846432        30846432  cudaDeviceSynchronize                                                           \n","    4.9        23675158           3       7891719.3         7445228         8722013  cudaFree                                                                        \n","    0.0           62320           1         62320.0           62320           62320  cudaLaunchKernel                                                                \n","\n","\n","\n","\n","Generating CUDA Kernel Statistics...\n","\n","Generating CUDA Memory Operation Statistics...\n","CUDA Kernel Statistics (nanoseconds)\n","\n","Time(%)      Total Time   Instances         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","  100.0          511489           1        511489.0          511489          511489  addVectorsInto                                                                  \n","\n","\n","CUDA Memory Operation Statistics (nanoseconds)\n","\n","Time(%)      Total Time  Operations         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   77.7        37266688         192        194097.3          192416          205120  [CUDA Unified Memory memcpy HtoD]                                               \n","   22.3        10707904          64        167311.0          166368          190048  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","CUDA Memory Operation Statistics (KiB)\n","\n","            Total      Operations            Average            Minimum            Maximum  Name                                                                            \n","-----------------  --------------  -----------------  -----------------  -----------------  --------------------------------------------------------------------------------\n","         393216.0             192             2048.0           2048.000             2048.0  [CUDA Unified Memory memcpy HtoD]                                               \n","         131072.0              64             2048.0           2048.000             2048.0  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","\n","\n","Generating Operating System Runtime API Statistics...\n","Operating System Runtime API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   49.5      1328906394          74      17958194.5           44601       100198555  poll                                                                            \n","   38.5      1033589588          69      14979559.2           23136       100128728  sem_timedwait                                                                   \n","   10.8       290458815         583        498214.1            1067        52478754  ioctl                                                                           \n","    1.0        26191994          88        297636.3            1683         8663678  mmap                                                                            \n","    0.2         6076388           3       2025462.7           40759         3309653  sem_wait                                                                        \n","    0.0          656213          73          8989.2            3722           22334  open64                                                                          \n","    0.0          234395           5         46879.0           34290           86609  pthread_create                                                                  \n","    0.0          133422          12         11118.5            7500           15194  write                                                                           \n","    0.0          126484          23          5499.3            1913           14561  fopen                                                                           \n","    0.0           92237           3         30745.7           22903           44594  fgets                                                                           \n","    0.0           80114          71          1128.4            1005            5095  fcntl                                                                           \n","    0.0           47884          14          3420.3            1715            5805  munmap                                                                          \n","    0.0           42672          16          2667.0            1708            4005  fclose                                                                          \n","    0.0           34023           5          6804.6            4592           10963  open                                                                            \n","    0.0           32690          14          2335.0            1316            4589  read                                                                            \n","    0.0           16656           3          5552.0            4525            6422  pipe2                                                                           \n","    0.0           13715           5          2743.0            2016            3952  mprotect                                                                        \n","    0.0           11113           2          5556.5            4542            6571  socket                                                                          \n","    0.0            7147           2          3573.5            2757            4390  fread                                                                           \n","    0.0            7030           1          7030.0            7030            7030  connect                                                                         \n","    0.0            2554           1          2554.0            2554            2554  bind                                                                            \n","    0.0            1747           1          1747.0            1747            1747  listen                                                                          \n","\n","\n","\n","\n","Generating NVTX Push-Pop Range Statistics...\n","NVTX Push-Pop Range Statistics (nanoseconds)\n","\n","\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GnwrG4A5-QY3","colab_type":"text"},"source":["After this series of refactors to use asynchronous prefetching, you should see that there are fewer, but larger, memory transfers, and, that the kernel execution time is significantly decreased."]},{"cell_type":"markdown","metadata":{"id":"15sSAACi-QY7","colab_type":"text"},"source":["---\n","## Iteratively Optimize an Accelerated SAXPY Application\n","\n","A basic accelerated [SAXPY](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_1) application.\n","\n","\n","Goal is to profile an accurate `saxpy` kernel, without modifying `N`, to run in under *100us*. "]},{"cell_type":"code","metadata":{"id":"u6ycBbpc-QY8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"da2f05cc-a3b8-46c8-ca60-ed17b2b843b1","executionInfo":{"status":"ok","timestamp":1591052984763,"user_tz":420,"elapsed":1982,"user":{"displayName":"Gabriele Boncoraglio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXEw7TWB8AnQR7GBopOPG42CBDV3rLZ-UejvU5SA=s64","userId":"05926223390448651175"}}},"source":["!nvcc -o saxpy 02-saxpy.cu -run"],"execution_count":19,"outputs":[{"output_type":"stream","text":["c[0] = 5, c[1] = 5, c[2] = 5, c[3] = 5, c[4] = 5, \n","c[4194299] = 5, c[4194300] = 5, c[4194301] = 5, c[4194302] = 5, c[4194303] = 5, \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uQrXC5sC-QY-","colab_type":"code","colab":{},"outputId":"e3cca461-867e-4856-da50-009d95377888"},"source":["!nsys profile --stats=true ./saxpy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","**** collection configuration ****\n","\tforce-overwrite = false\n","\tstop-on-exit = true\n","\texport_sqlite = true\n","\tstats = true\n","\tcapture-range = none\n","\tstop-on-range-end = false\n","\tBeta: ftrace events:\n","\tftrace-keep-user-config = false\n","\ttrace-GPU-context-switch = false\n","\tdelay = 0 seconds\n","\tduration = 0 seconds\n","\tkill = signal number 15\n","\tinherit-environment = true\n","\tshow-output = true\n","\ttrace-fork-before-exec = false\n","\tsample_cpu = true\n","\tbacktrace_method = LBR\n","\twait = all\n","\ttrace_cublas = false\n","\ttrace_cuda = true\n","\ttrace_cudnn = false\n","\ttrace_nvtx = true\n","\ttrace_mpi = false\n","\ttrace_openacc = false\n","\ttrace_vulkan = false\n","\ttrace_opengl = true\n","\ttrace_osrt = true\n","\tosrt-threshold = 0 nanoseconds\n","\tcudabacktrace = false\n","\tcudabacktrace-threshold = 0 nanoseconds\n","\tprofile_processes = tree\n","\tapplication command = ./saxpy\n","\tapplication arguments = \n","\tapplication working directory = /dli/task\n","\tNVTX profiler range trigger = \n","\tNVTX profiler domain trigger = \n","\tenvironment variables:\n","\tCollecting data...\n","c[0] = 5, c[1] = 5, c[2] = 5, c[3] = 5, c[4] = 5, \n","c[4194299] = 5, c[4194300] = 5, c[4194301] = 5, c[4194302] = 5, c[4194303] = 5, \n","\tGenerating the /dli/task/report9.qdstrm file.\n","\tCapturing raw events...\n","\t1070 total events collected.\n","\tSaving diagnostics...\n","\tSaving qdstrm file to disk...\n","\tFinished saving file.\n","\n","\n","Importing the qdstrm file using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/QdstrmImporter.\n","\n","Importing...\n","\n","Importing [==================================================100%]\n","Saving report to file \"/dli/task/report9.qdrep\"\n","Report file saved.\n","Please discard the qdstrm file and use the qdrep file instead.\n","\n","Removed /dli/task/report9.qdstrm as it was successfully imported.\n","Please use the qdrep file instead.\n","\n","Exporting the qdrep file to SQLite database using /opt/nvidia/nsight-systems/2019.5.2/host-linux-x64/nsys-exporter.\n","\n","Exporting 1040 events:\n","\n","0%   10   20   30   40   50   60   70   80   90   100%\n","|----|----|----|----|----|----|----|----|----|----|\n","***************************************************\n","\n","Exported successfully to\n","/dli/task/report9.sqlite\n","\n","Generating CUDA API Statistics...\n","CUDA API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   96.3       248315341           3      82771780.3           34002       248246650  cudaMallocManaged                                                               \n","    1.8         4620918           1       4620918.0         4620918         4620918  cudaDeviceSynchronize                                                           \n","    1.1         2890072           3        963357.3          935012         1019789  cudaFree                                                                        \n","    0.7         1927207           3        642402.3           10392         1762454  cudaMemPrefetchAsync                                                            \n","    0.0           59525           1         59525.0           59525           59525  cudaLaunchKernel                                                                \n","\n","\n","\n","\n","Generating CUDA Kernel Statistics...\n","\n","Generating CUDA Memory Operation Statistics...\n","CUDA Kernel Statistics (nanoseconds)\n","\n","Time(%)      Total Time   Instances         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","  100.0           70501           1         70501.0           70501           70501  saxpy                                                                           \n","\n","\n","CUDA Memory Operation Statistics (nanoseconds)\n","\n","Time(%)      Total Time  Operations         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   99.6         4672320          24        194680.0          192576          199552  [CUDA Unified Memory memcpy HtoD]                                               \n","    0.4           16512           4          4128.0            2080            5920  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","CUDA Memory Operation Statistics (KiB)\n","\n","            Total      Operations            Average            Minimum            Maximum  Name                                                                            \n","-----------------  --------------  -----------------  -----------------  -----------------  --------------------------------------------------------------------------------\n","          49152.0              24             2048.0           2048.000             2048.0  [CUDA Unified Memory memcpy HtoD]                                               \n","            128.0               4               32.0              4.000               60.0  [CUDA Unified Memory memcpy DtoH]                                               \n","\n","\n","\n","\n","Generating Operating System Runtime API Statistics...\n","Operating System Runtime API Statistics (nanoseconds)\n","\n","Time(%)      Total Time       Calls         Average         Minimum         Maximum  Name                                                                            \n","-------  --------------  ----------  --------------  --------------  --------------  --------------------------------------------------------------------------------\n","   45.4       403730344          20      20186517.2           23680       100120544  sem_timedwait                                                                   \n","   43.0       381572181          25      15262887.2           44827       100112925  poll                                                                            \n","   10.7        95002519         579        164080.3            1032        20447171  ioctl                                                                           \n","    0.6         5362097          87         61633.3            1532          899192  mmap                                                                            \n","    0.1         1132422           3        377474.0           50247          541980  sem_wait                                                                        \n","    0.1          683237          73          9359.4            3760           25752  open64                                                                          \n","    0.0          211281           5         42256.2           34431           62288  pthread_create                                                                  \n","    0.0          135962          12         11330.2            7625           16384  write                                                                           \n","    0.0          129159          23          5615.6            1850           15446  fopen                                                                           \n","    0.0           93534           3         31178.0           23267           45062  fgets                                                                           \n","    0.0           76978          68          1132.0            1007            4859  fcntl                                                                           \n","    0.0           44445           5          8889.0            4389           19385  open                                                                            \n","    0.0           42100          13          3238.5            1667            6147  munmap                                                                          \n","    0.0           41610          16          2600.6            1638            3808  fclose                                                                          \n","    0.0           31963          14          2283.1            1247            4156  read                                                                            \n","    0.0           18213           3          6071.0            5490            6825  pipe2                                                                           \n","    0.0           12029           5          2405.8            2016            3374  mprotect                                                                        \n","    0.0           11248           2          5624.0            4258            6990  socket                                                                          \n","    0.0            9027           2          4513.5            4302            4725  fread                                                                           \n","    0.0            7635           1          7635.0            7635            7635  connect                                                                         \n","    0.0            2579           1          2579.0            2579            2579  bind                                                                            \n","    0.0            2373           1          2373.0            2373            2373  listen                                                                          \n","\n","\n","\n","\n","Generating NVTX Push-Pop Range Statistics...\n","NVTX Push-Pop Range Statistics (nanoseconds)\n","\n","\n","\n","\n"],"name":"stdout"}]}]}